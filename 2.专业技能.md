1. # 项目名称:后古艺术家

   项目介绍:后古艺术家是一款关于摄影等服务的小程序。我的任务是帮助后古优化内部IT运维体系,升级监控及故障处理能力。

   项目职责:

   1. 分析IT基础设施、服务器性能监控现状,提出监控优化方案
   2. 使用资源监控框架如Prometheus、Zabbix等作为监控agents,实现统一的性能数据采集与展示
   3. 基于阿里云tracer等技术的分布式追踪系统,优化故障定位流程
   4. 使用ELK日志分析平台,提高IT异常诊断效率;
   5. 使用动态资源调配机制VMware,Docker,RabbitMQ提高业务应对能力;
   6. 通过与AI的交互操作，优化配置和变更管理流程，减少人为错误，并定期进行经营性演练和冒烟测试，以验证系统治理能力的实现。

   项目结果:

   1. 实现全面动态IT资源监控与管理;
   2. 提升给用户的服务可用性和响应能力;
   3. 加强运维治理,降低因系统问题导致的损失;
   4. 助力后古业务高速和规模化发展。
   
   # 2.项目名称:美食之家
   
    项目描述:美食之家小程序。我的任务是帮助小程序优化内部IT运维体系,升级监控及故障处理能力。
   
   日常任务:
    1.编写Shell和Python脚本实现项目的自动化部署,大幅提升release效率 
   2.使用Keepalived和Nginx实现服务的高可用性,确保系统稳定可靠
    3.对核心服务组件制定监控策略,基于Prometheus采集关键性能指标 
   4.使用Grafana展示各项运维监控面板,直观反映系统状态 
   5.搭建EFK(Elasticsearch+Fluentd+Kibana)日志分析平台,快速定位故障
    6.增加WAF防护,修复Web漏洞,提升安全性
    7.基于Kubernetes等技术实现服务的弹性伸缩,提高资源利用率
    8.在性能测试中,与AI进行测试结果分析,利用AI的计算能力帮助发现系统瓶颈
    9.在资源管理中,与AI进行方案讨论,由AI给出资源调度和分配的建议,从而进行优化
    10.与AI交互,对在线人数的时间节点及反馈数据进行分析, 通过数据反映受众人数的真实性 
   11.评估并选型云服务,制定云迁移策略,降低基础设施成本 
   12.基于阿里云tracer等技术的分布式追踪系统,优化故障定位流程
   13.通过 WebSocket 技术实现了弹幕交流 ,减少了系统的开销 
   14.使用动态资源调配机制VMware,Docker,RabbitMQ提高业务应对能力 
   15.进行Tomcat+Nginx 集群部署,提升系统的并发处理能力 16.消息收集流转整合到手机端,接口做手机端适配,安全漏洞修复

## 补充：

**监控**(使用成熟的开源监控框架是实现统一监控的一个很好的选择。具体可以考虑:

1. 选择Prometheus作为监控框架。它属于时序数据库,能很好地收集和存储时序数据。
2. 安装Prometheus Server,用来抓取和存储监控指标。
3. 部署Prometheus Node Exporter作为exporter,安装在各监控对象上如服务器、数据库等。它会将机器信息如CPU、内存利用率等暴露为Prometheus可以抓取的指标。
4. 设计监控规则。例如为业务关键组件设定阈值报警。
5. 使用Prometheus客户端库为特定业务添加自定义指标。
6. 部署Grafana作为可视化展示平台。从Prometheus抓取数据源,设计各类Dashboard面板。
7. 考虑是否同时保留Zabbix等其他监控系统。两者结合使用,利用各自长处。
8. 使用Configuration Management工具提高自动化程度,实现统一监控配置管理。

以Prometheus为核心,标准化指标采集存储和展现,可以有效实现后古IT资源的统一监控。同时也方便日后根据业务扩充监控范围。)

**追踪**(作为初级运维程序员,实现基于阿里云Trace的分布式追踪系统,可以考虑以下步骤:

1. 了解分布式追踪系统原理。微服务架构下服务调用关系错综复杂,分布式追踪可以清晰展现请求流程。
2. 研读阿里云Trace文档,了解它支持的tracing capabilities。Trace可以集中收集各个微服务节点的指标和调用关系链。
3. 下载和安装阿里云TSF平台。它提供Trace Agent一键部署,支持多个语言追踪。
4. 按文档说明在TSF平台上注册应用、微服务。标记服务名和版本号等元数据信息。
5. 在代码中引入阿里云提供的客户端SDK,实现请求上下文传递。例如Java服务添加Maven依赖。
6. 关键业务逻辑处添加调用关系追踪代码。追踪服务入口、RPC调用、数据库查询等节点。
7. 部署Trace Agent到生产环境中。Agent将追踪日志上报给TSF中心平台。
8. 在TSF控制台查看追踪结果,分析调用关系和慢查询点。进行性能调优。
9. 基于追踪数据,定义SLA指标和报警规则,实现监测和治理。

以上步骤利用成熟产品能力,初级程序员也可轻松实现在企业级微服务架构下的分布式追踪。)

**ELK**(使用ELK(Elasticsearch、Logstash、Kibana)日志分析平台提高IT异常诊断效率的主要流程包括:

1. 规划ELK集群架构。决定ES节点数,是否使用数据节点等。
2. 安装并配置好ELK每个组件。ES集群安装在若干服务器上,Logstash和Kibana单独安装。
3. 设计日志收集规则。在Logstash配置从各类服务如Web服务器、App服务器等采集日志到ES的数据格式。
4. 开发Logstash插件。针对特定格式的业务日志开发输入和过滤插件。
5. 在ELK集群中导入历史日志。使用Logstash或Filebeat将储存的旧日志导入到ES。
6. 在Kibana创建Index pattern。说明日志字段及其数据类型。
7. 使用Kibana带来的控制台、惯例等工具进行数据探索和分析。
8. 基于分析结果设计 Dashboard 查询面板。
9. 为面板添加警报规则。当发生问题自动提示运维人员。
10. 把ELK部署到生产,实时监控系统各组件日志。一旦报错可快速定位原因。
11. 后续根据演练结果持续优化ELK与业务系统集成。

以上流程可以帮助初级运维人员快速掌握ELK,为IT异常提供有效分析支持。)

**AI**(与AI的交互可以通过以下方式实现：

1. 自动化配置管理：利用AI技术，可以开发智能配置管理系统，通过与AI进行交互，实现自动化的配置管理。例如，可以使用自然语言处理（NLP）技术，让用户通过语音或文本与AI进行对话，提供配置需求，AI则可以解析用户需求并自动完成相应的配置操作，从而减少人为错误。
2. 自动化变更管理：AI可以发挥作用，帮助管理和监控系统变更。通过与AI进行交互，可以实现自动化的变更管理流程。AI可以分析和评估变更请求，并提供准确的建议和决策支持，帮助减少人为错误，并确保变更的合规性和安全性。
3. 智能演练和冒烟测试：使用AI技术，可以开发智能演练和冒烟测试系统。通过与AI交互，可以进行定期的演练和冒烟测试，验证系统的治理能力。AI可以模拟各种场景和情况，并提供实时反馈和建议，帮助优化系统的运行和管理。

总之，通过与AI的交互操作，可以实现配置管理和变更管理的自动化，并进行经营性演练和冒烟测试，从而提高系统的治理能力，并减少人为错误的发生。)

## 美食之家

我现在是面试官，你说你编写Shell和Python脚本实现项目的自动化部署,大幅提升release效率。可以给我简单介绍一下吗？
~编写脚本自动化包管理(使用Python脚本调用系统包管理工具,自动化安装项目各种依赖,如数据库、缓存等。)

```
～你是如何编写脚本自动化包管理的，可以简单说一下过程吗

查明项目的依赖
·查找项目的配置文件，安装文档等，查明项目运行所依赖的所有软件包
选择合适的包管理器
·根据项目的操作系统选择对应的包管理工具，例如apt，yum等
编写包安装函数
·针对包管理器，编写函数，调用命令行接口自动安装制定软件包
汇总依赖列表
·将所有项目依赖写入一个列表中，作为自动化脚本的输入参数
编排调用函数
·编写脚本主逻辑，遍历Dependency列表，循环调用包安装函数
添加日志和压测
·在脚本添加日志记录，以及对安装结果的检查，打印输出等
测试调优
·对脚本进行足够的测试，确保能自动化安装所有依赖，并不断优化脚本的健壮性
```



~自动化配置管理(脚本可以替代手动修改配置文件,实现一致的配置部署。)

```
～～那你自动化配置管理的历程也和编写脚本自动化包管理的流程一样吗

·是的有类似的流程，但也有所不同
·分析配置结构，检查项目用了哪些配置文件，以及文件内参数的结构和作用
·选择配置工具，工具不同配置方式，选择json等格式的可以通过JQ工具解析
·编写读取函数，针对各配置文件，编写读取其参数的函数
·编写更新函数
·汇总参数列表，手机所有需要自动设置的关键配置项和值
·增加检测回滚
·测试迭代
```



~一键安装部署(将项目安装部署的整个过程编排到脚本,一键执行即可完成部署。)
~自动化测试(编写脚本调用测试框架,在部署后自动进行集成测试。)
~发布自动回滚(如果发布过程失败,可以通过脚本快速回滚到原版本。)

```
~~那你在做发布自动回滚脚本的时候有遇到什么问题吗？
·版本控制不完善，因代码版本管理不规范，导致无法回滚到清晰的历史版本
·回滚效果不完全，已执行的数据库迁移等
·项目依赖可能与历史版本不兼容，回滚导致依赖问题
·数据丢失，由于没有做好数据迁移和备份
·回滚时间长，服务间依赖复杂
·审核流程缺失，没有增加人工审批环节
～～解决方案：
·做好版本控制，记录清晰版本信息
·设计可逆的编排流程
·回滚后检查依赖并重建
·增加数据库备份恢复机制
·优化服务解耦，加快回滚速度
·在回滚流程中增加审批环节
```



~调用CI/CD流水线(通过脚本触发Jenkins等CI/CD平台,无缝连接自动化流程)

```
～～你调用ci/cd流水线的过程可以简单描述一下吗？
·查明流水线的触发方式，CI/CD提供了Webhook，API等接口用于触发
·根据提供的触发方式，调研相关接口的参数，格式，认证等要求
·编写触发函数，根据接口要求，编写封装了触发逻辑的函数，实现调用接口触发流水线
·传入参数处理，在触发函数中处理好需要传递给流水线的变量，参数
·调用触发函数，在自动部署脚本的适当位置，调用编写的触发函数，激活流水线。
·检查执行结果，通过日志或回调接口检查流水线是否被触发
·继续集成，可以继续通过脚本集成流水线的后续过程，测试或者发布。
~~通过脚本触发Jenkins的流程可以介绍一下吗
·获取Jenkins为脚本生成一个APiToken，用于脚本验证和授权
·查找触发接口，Jenkins提供了诸如build，buildwithparameters等触发build的restApi接口
·编写触发函数，使用请求库编写封装了请求接口的函数，传入需要的参数
·准备参数，组装触发build所需的参数，如job名称，分支，版本号
·调用触发函数，在自动化脚本适当时机调用触发函数并传入参数
·处理异步过程，触发build后可以继续通过脚本跟进后续的异步执行过程
·获取执行结果，通过解析JenkinsApi返回结果判断构建是否成功执行
·错误处理，增加重试，日志记录等机制，提高脚本健硕性。
```

我现在是面试官，说一下使用Keepalived和Nginx实现服务的高可用性的过程