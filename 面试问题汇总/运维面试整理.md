###### [输入[www.douyin.com](http://www.douyin.com)会发生什么(dns tcp连接 http请求 渲染解析)]

1.检查本地缓存,资源已缓存就直接缓存
2.浏览器对域名进行DNS解析获得其ip地址
3.浏览器与抖音服务器建立TCP三次握手
4.浏览器发送HTTP请求给服务器，请求get，路径
5.服务器收到请求生成HTML内容
6.服务器将响应回传给浏览器，响应包括响应码和HTML
7.浏览器解析render HTML内容，请求HTML静态内容
8.浏览器渲染页面完成抖音的加载
9.通过AJAX进行后续页面交互
10.服务器继续响应后续内容，返回更新内容
11.浏览器关闭页面时，与服务器断开TCP连接

##### DNS解析过程/工作原理

1.本地DNS缓存。当浏览器需要解析域名的时候，会先检查本地缓存。
2.递归查询。本地缓存没有命中浏览器会将域名解析请求发送给配置的递归DNS服务器，通常是本地ISP提供的DNS服务器。
3.根域名服务器查询。递归DNS服务器会首先查询这个，获得顶级域的权威DNS服务器地址。
4.TLD域名服务器查询。得到顶级域权威服务器地址后，再向其查询获得负责.com域的权威DNS服务器。
5.权威DNS服务器查询。最后递归DNS服务器向.com域权威服务器发起递归查询w w w.example.com，获得最终解析结果IP地址。
6.返回解析结果。权威DNS服务器返回解析结果IP地址给递归DNS服务器，递归服务器再返回给客户端浏览器。时间大概几十到几百毫秒之间。

##### TCP需要三次握手来建立连接

1.客户端发送SYN包。发synchronize包到服务器端初始化连接，该报文不包含数据只有初始化序列号ISN。
2.服务器响应SYN+ACK包。服务器收到SYN包，需要对请求确认，会回传一个SYN+ACK包，确认号(AN)=客户端ISN+1，同时自己产生ISN。
3.客户端发送ACK包。确认号为服务器端ISN+1，三次握手完成。
三次握手为了解决“已失效连接请求报文段突然又传到服务端的问题”，既可以开始传数据了。

###### Https协议的工作原理。

1.建立SSL/TLS通道。浏览器和Web服务器通过SSL/TLS协议进行加密通信，该协议建立在TCP之上，用于两端点间数据的加密传输。
2.服务器证书验证。浏览器会验证服务器的数字证书是否由浏览器可信的证书颁发机构签名，验证合法性。
3.协商加密算法。浏览器和服务器协商使用对称加密算法，比如AES，用于后续的数据加密。
4.生成会话密钥。服务器使用自己的私钥生成一个随机的会话密钥，通过公钥加密发送给浏览器。
5.数据加密传输。浏览器使用会话密钥加密HTTP报文的数据，使用SSL/TLS通道传送到服务器端。服务器端解密数据。
6.连接结束。SSL/TLS通道种植，浏览器和服务器删除保存的密钥数据。
HTTPS保证通信内容不被窃听，传输安全。
7.SSL，Secure Sockets Layer/TLS，Transport Layer Security，安全协议，用于web间加密传输，依托加密算法和证书。
8.AES/Advanced Encryption Standard，对称加密算法，美国联邦政府采用的一种区块加密标准。

###### ping的过程

1.本地执行ping，指定ping的目标IP地址。
2.ping命令构造一个ICMP Echo Request数据包，包含了标识符和序号。
3.本地主机发送ICMP Echo Reques到目标主机。
4.目标主机收到，会在IP头部中把源和目标IP地址互换，同时构造一个ICMP Echo Reply数据包。
5.目标主机发送ICMP Echo Reply作为响应回应本地主机。
6.本地主机收到ICMP Echo Reply，会检查标识符和序号是否与发送的数据包匹配。
7.如果匹配，本地系统会显示出响应时间和TTL(Time to Live)值。
8.超时未回复表示主机不可达，ping命令会继续每隔一段时间发送ICMP请求来测试连接情况。
9.ping命令可以测试网络的连通性和延迟。

###### 跨域Cross-Origin

1.浏览器对javascript的同源策略的限制。
2.同源策略要求源相同才能访问，源是origin指的是协议，域名和端口号。
3.跨域问题主要Throught解决方案有CORS(跨域资源共享):服务端在HTTP头中添加Access-Control-Allow-Origin等响应头，表示允许制定来源的跨域请求。JSNOP:利用script标签可以跨域的特点,通过javascript callback的形式实现跨域通信。代理:通过同源代理服务器进行转发请求，避免跨域。nginx反向代理:可以配置nginx转发跨域请求，实现跨域访问。websocket:浏览器和服务器简历websocket连接，实现持久话的跨域通信。serverless:使用无服务器架构，通过服务器less功能实现跨域。

###### **监控**

(使用成熟的开源监控框架是实现统一监控的一个很好的选择。具体可以考虑:

1. 选择Prometheus作为监控框架。它属于时序数据库,能很好地收集和存储时序数据。
2. 安装Prometheus Server,用来抓取和存储监控指标。
3. 部署Prometheus Node Exporter作为exporter,安装在各监控对象上如服务器、数据库等。它会将机器信息如CPU、内存利用率等暴露为Prometheus可以抓取的指标。
4. 设计监控规则。例如为业务关键组件设定阈值报警。
5. 使用Prometheus客户端库为特定业务添加自定义指标。
6. 部署Grafana作为可视化展示平台。从Prometheus抓取数据源,设计各类Dashboard面板。
7. 考虑是否同时保留Zabbix等其他监控系统。两者结合使用,利用各自长处。
8. 使用Configuration Management工具提高自动化程度,实现统一监控配置管理。

以Prometheus为核心,标准化指标采集存储和展现,可以有效实现后古IT资源的统一监控。同时也方便日后根据业务扩充监控范围。)

###### **追踪**

(作为初级运维程序员,实现基于阿里云Trace的分布式追踪系统,可以考虑以下步骤:

1. 了解分布式追踪系统原理。微服务架构下服务调用关系错综复杂,分布式追踪可以清晰展现请求流程。
2. 研读阿里云Trace文档,了解它支持的tracing capabilities。Trace可以集中收集各个微服务节点的指标和调用关系链。
3. 下载和安装阿里云TSF平台。它提供Trace Agent一键部署,支持多个语言追踪。
4. 按文档说明在TSF平台上注册应用、微服务。标记服务名和版本号等元数据信息。
5. 在代码中引入阿里云提供的客户端SDK,实现请求上下文传递。例如Java服务添加Maven依赖。
6. 关键业务逻辑处添加调用关系追踪代码。追踪服务入口、RPC调用、数据库查询等节点。
7. 部署Trace Agent到生产环境中。Agent将追踪日志上报给TSF中心平台。
8. 在TSF控制台查看追踪结果,分析调用关系和慢查询点。进行性能调优。
9. 基于追踪数据,定义SLA指标和报警规则,实现监测和治理。

以上步骤利用成熟产品能力,初级程序员也可轻松实现在企业级微服务架构下的分布式追踪。)

###### **ELK**

(使用ELK(Elasticsearch、Logstash、Kibana)日志分析平台提高IT异常诊断效率的主要流程包括:

1. 规划ELK集群架构。决定ES节点数,是否使用数据节点等。
2. 安装并配置好ELK每个组件。ES集群安装在若干服务器上,Logstash和Kibana单独安装。
3. 设计日志收集规则。在Logstash配置从各类服务如Web服务器、App服务器等采集日志到ES的数据格式。
4. 开发Logstash插件。针对特定格式的业务日志开发输入和过滤插件。
5. 在ELK集群中导入历史日志。使用Logstash或Filebeat将储存的旧日志导入到ES。
6. 在Kibana创建Index pattern。说明日志字段及其数据类型。
7. 使用Kibana带来的控制台、惯例等工具进行数据探索和分析。
8. 基于分析结果设计 Dashboard 查询面板。
9. 为面板添加警报规则。当发生问题自动提示运维人员。
10. 把ELK部署到生产,实时监控系统各组件日志。一旦报错可快速定位原因。
11. 后续根据演练结果持续优化ELK与业务系统集成。

以上流程可以帮助初级运维人员快速掌握ELK,为IT异常提供有效分析支持。)

###### **AI**

(与AI的交互可以通过以下方式实现：

1. 自动化配置管理：利用AI技术，可以开发智能配置管理系统，通过与AI进行交互，实现自动化的配置管理。例如，可以使用自然语言处理（NLP）技术，让用户通过语音或文本与AI进行对话，提供配置需求，AI则可以解析用户需求并自动完成相应的配置操作，从而减少人为错误。
2. 自动化变更管理：AI可以发挥作用，帮助管理和监控系统变更。通过与AI进行交互，可以实现自动化的变更管理流程。AI可以分析和评估变更请求，并提供准确的建议和决策支持，帮助减少人为错误，并确保变更的合规性和安全性。
3. 智能演练和冒烟测试：使用AI技术，可以开发智能演练和冒烟测试系统。通过与AI交互，可以进行定期的演练和冒烟测试，验证系统的治理能力。AI可以模拟各种场景和情况，并提供实时反馈和建议，帮助优化系统的运行和管理。

总之，通过与AI的交互操作，可以实现配置管理和变更管理的自动化，并进行经营性演练和冒烟测试，从而提高系统的治理能力，并减少人为错误的发生。)

###### 美食之家

我现在是面试官，你说你编写Shell和Python脚本实现项目的自动化部署,大幅提升release效率。可以给我简单介绍一下吗？
~编写脚本自动化包管理(使用Python脚本调用系统包管理工具,自动化安装项目各种依赖,如数据库、缓存等。)

```
～你是如何编写脚本自动化包管理的，可以简单说一下过程吗

查明项目的依赖
·查找项目的配置文件，安装文档等，查明项目运行所依赖的所有软件包
选择合适的包管理器
·根据项目的操作系统选择对应的包管理工具，例如apt，yum等
编写包安装函数
·针对包管理器，编写函数，调用命令行接口自动安装制定软件包
汇总依赖列表
·将所有项目依赖写入一个列表中，作为自动化脚本的输入参数
编排调用函数
·编写脚本主逻辑，遍历Dependency列表，循环调用包安装函数
添加日志和压测
·在脚本添加日志记录，以及对安装结果的检查，打印输出等
测试调优
·对脚本进行足够的测试，确保能自动化安装所有依赖，并不断优化脚本的健壮性
```



~自动化配置管理(脚本可以替代手动修改配置文件,实现一致的配置部署。)

```
～～那你自动化配置管理的历程也和编写脚本自动化包管理的流程一样吗

·是的有类似的流程，但也有所不同
·分析配置结构，检查项目用了哪些配置文件，以及文件内参数的结构和作用
·选择配置工具，工具不同配置方式，选择json等格式的可以通过JQ工具解析
·编写读取函数，针对各配置文件，编写读取其参数的函数
·编写更新函数
·汇总参数列表，手机所有需要自动设置的关键配置项和值
·增加检测回滚
·测试迭代
```

~一键安装部署(将项目安装部署的整个过程编排到脚本,一键执行即可完成部署。)
~自动化测试(编写脚本调用测试框架,在部署后自动进行集成测试。)
~发布自动回滚(如果发布过程失败,可以通过脚本快速回滚到原版本。)

```
~~那你在做发布自动回滚脚本的时候有遇到什么问题吗？
·版本控制不完善，因代码版本管理不规范，导致无法回滚到清晰的历史版本
·回滚效果不完全，已执行的数据库迁移等
·项目依赖可能与历史版本不兼容，回滚导致依赖问题
·数据丢失，由于没有做好数据迁移和备份
·回滚时间长，服务间依赖复杂
·审核流程缺失，没有增加人工审批环节
～～解决方案：
·做好版本控制，记录清晰版本信息
·设计可逆的编排流程
·回滚后检查依赖并重建
·增加数据库备份恢复机制
·优化服务解耦，加快回滚速度
·在回滚流程中增加审批环节
```



~调用CI/CD流水线(通过脚本触发Jenkins等CI/CD平台,无缝连接自动化流程)

```
～～你调用ci/cd流水线的过程可以简单描述一下吗？
·查明流水线的触发方式，CI/CD提供了Webhook，API等接口用于触发
·根据提供的触发方式，调研相关接口的参数，格式，认证等要求
·编写触发函数，根据接口要求，编写封装了触发逻辑的函数，实现调用接口触发流水线
·传入参数处理，在触发函数中处理好需要传递给流水线的变量，参数
·调用触发函数，在自动部署脚本的适当位置，调用编写的触发函数，激活流水线。
·检查执行结果，通过日志或回调接口检查流水线是否被触发
·继续集成，可以继续通过脚本集成流水线的后续过程，测试或者发布。
~~通过脚本触发Jenkins的流程可以介绍一下吗
·获取Jenkins为脚本生成一个APiToken，用于脚本验证和授权
·查找触发接口，Jenkins提供了诸如build，buildwithparameters等触发build的restApi接口
·编写触发函数，使用请求库编写封装了请求接口的函数，传入需要的参数
·准备参数，组装触发build所需的参数，如job名称，分支，版本号
·调用触发函数，在自动化脚本适当时机调用触发函数并传入参数
·处理异步过程，触发build后可以继续通过脚本跟进后续的异步执行过程
·获取执行结果，通过解析JenkinsApi返回结果判断构建是否成功执行
·错误处理，增加重试，日志记录等机制，提高脚本健硕性。
```
